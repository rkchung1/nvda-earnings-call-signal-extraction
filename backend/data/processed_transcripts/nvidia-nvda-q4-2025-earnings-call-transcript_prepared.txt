Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal 2026. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 26, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. Confine a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette M. Kress
Chief Financial Officer, Executive Vice President
Thanks, Stewart. Q4 was another record quarter. Revenue of 39.3 billion was up 12 sequentially and up 78 year on year and above our outlook of 37.5 billion. For fiscal 2025 revenue was 130.5 billion, up 114 from the prior year.
Let's start with Data Center. Data center revenue for fiscal 2025 was 115.2 billion, more than doubling from the prior year. In the fourth quarter, Data Center revenue of 35.6 billion was a record, up 16 sequentially and 93 year on year as the Blackwell ramp commenced and Hopper 200 continued sequential growth. In Q4, Blackwell sales exceeded our expectations.
We delivered 11 billion of Blackwell revenue to meet strong demand. This is the fastest product ramp in our company's history, unprecedented in its speed and scale. Blackwell production is in full-year across multiple configurations, and we are increasing supply quickly expanding customer adoption. Our Q4 Data Center compute revenue jumped 18 sequentially and over 2x year on year.
Customers are racing to scale infrastructure to train the next generation of cutting-edge models and unlock the next level of AI capabilities. With Blackwell, it will be common for these clusters to start with 100,000 GPUs or more. Shipments have already started for multiple infrastructures of this size. Post-training and model customization are fueling demand for NVIDIA infrastructure and software as developers and enterprises leverage techniques such as fine-tuning reinforcement learning and distillation to tailor models for domain-specific use cases.
Hugging Face alone hosts over 90,000 derivatives freighted from the Llama foundation model. The scale of post-training and model customization is massive and can collectively demand orders of magnitude, more compute than pretraining. Our inference demand is accelerating, driven by test time scaling and new reasoning models like OpenAI's o3, DeepSeek-R1, and Grok 3. Long-thinking reasoning AI can require 100x more compute per task compared to one-shot inferences.
Blackwell was architected for reasoning AI inference. Blackwell supercharges reasoning AI models with up to 25x higher token throughput and 20x lower cost versus Hopper 100. It is revolutionary transformer engine is built for LLM and mixture of experts inference. And its NVLink Domain delivers 14x the throughput of PCIe Gen 5, ensuring the response time, throughput, and cost efficiency needed to tackle the growing complexity of infants of scale.
Companies across industries are tapping into NVIDIA's whole STAG inference platform to boost performance and slash costs. Now, tripled inference throughput and cut costs by 66 , using NVIDIA TensorRT for its screenshot feature. Perplexity sees 435 million monthly queries and reduced its inference costs 3x with NVIDIA Triton Inference Server and TensorRT-LLM. Microsoft Bing achieved a 5x speed up at major TCO savings for visual search across billions of images with NVIDIA, TensorRT, and acceleration libraries.
Blackwell has great demand for inference. Many of the early GB200 deployments are earmarked for inference, a first for a new architecture. Blackwell addresses the entire AI market from pretraining, post-training to inference across cloud, to on-premise, to enterprise. CUDA's programmable architecture accelerates every AI model and over 4,400 applications, ensuring large infrastructure investments against obsolescence in rapidly evolving markets.
Our performance and pace of innovation is unmatched. We're driven to a 200x reduction in inference costs in just the last two years. We delivered the lowest TCO and the highest ROI. And full stack optimizations for NVIDIA and our large ecosystem, including 5.9 million developers continuously improve our customers' economics.
In Q4, large CSPs represented about half of our data center revenue. and these sales increased nearly 2x year on year. Large CSPs were some of the first to stand up Blackwell with Azure, GCP, AWS, and OCI bringing GB200 systems to cloud regions around the world to meet certain surging customer demand for AI. Regional cloud hosting NVIDIA GPUs increased as a percentage of data center revenue, reflecting continued AI factory build-outs globally and rapidly rising demand for AI reasoning models and agents.
We've launched a 100,000 GB200 cluster-based incidents with NVLink Switch and Quantum 2 InfiniBand. Consumer Internet revenue grew 3x year on year, driven by an expanding set of generative AI and deep learning use cases. These include recommender systems, vision, language understanding, synthetic data generation search, and agentic AI. For example, xAI is adopting the GB200 to train and inference its next generation of Grok AI models.
Meta's cutting-edge Andromeda advertising engine runs on NVIDIA's Grace Hopper Superchip serving vast quantities of ads across Instagram, Facebook applications. Andromeda harnesses Grace Hopper's fast interconnect and large memory to boost inference throughput by 3x, enhance ad personalization, and deliver meaningful jumps in monetization and ROI. Enterprise revenue increased nearly 2x year on accelerating demand for model fine-tuning, RAG, and agentic AI workflows, and GPU-accelerated data processing. We introduced NVIDIA Llama Nemotron model family NIMs to help developers create and deploy AI agents across a range of applications including customer support, fraud detection, and product supply chain and inventory management.
Leading AI agent platform providers, including SAP and ServiceNow, are among the first to use new models. Health care leaders IQVIA, Illumina, Mayo Clinic, and Arc Institute are using NVIDIA AI to speed drug discovery enhanced genomic research and Pioneer advanced healthcare services with generative and agentic AI. As AI expands beyond the digital world, NVIDIA infrastructure and software platforms are increasingly being adopted to power robotics and physical AI development. One of the early and largest robotics applications and autonomous vehicles where virtually, every AV company is developing on NVIDIA in the data center, the car, or both.
NVIDIA's automotive vertical revenue is expected to grow to approximately 5 billion this fiscal year. At CES, Hyundai Motor Group announced it is adopting NVIDIA technologies to accelerate AV and robotics development and smart factory initiatives. Vision transformers, self-supervised learning, multimodal sensor fusion, and high-fidelity simulation are driving breakthroughs in AV development and will require 10x more compute. At CES, we announced the NVIDIA COSMO World Foundation model platform.
Just as language, foundation models have revolutionized Language AI, Cosmos is a physical AI to revolutionize robotics. The robotics and automotive companies, including ridesharing giant Uber, are among the first to adopt the platform. From a geographic perspective, sequential growth in our Data Center revenue was strongest in the U.S., driven by the initial ramp up Blackwell. Countries across the globe are building their AI ecosystem as demand for compute infrastructure is surging.
France's EUR 100 billion AI investment and the EU's EUR 200 billion invest AI initiatives offer a glimpse into the build-out to set redefined global AI infrastructure in the coming years. Now, as a percentage of total Data Center revenue, data center sales in China remained well below levels seen on the onset of export controls. Absent any change in regulations, we believe that China shipments will remain roughly at the current percentage. The market in China for data center solutions remains very competitive.
We will continue to comply with export controls while serving our customers. Networking revenue declined 3 sequentially. Our networking attached to GPU compute systems is robust at over 75 . We are transitioning from small NVLink 8 with InfiniBand, to large NVLink 72 with Spectrum-X.
Spectrum-X and NVLink Switch revenue increased and represents a major new growth vector. We expect networking to return to growth in Q1. AI requires a new class of networking. NVIDIA offers NVLink Switch systems for scale-up compute.
For scale-out, we offer quantum incentive for HPC supercomputers and Spectrum X for Ethernet environments. Spectrum-X enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure, OCI, CoreWeave, and others are building large AI factories with Spectrum-X. The first Stargate data centers will use Spectrum-X.
Yesterday, Cisco announced integrating Spectrum-X into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Ethernet to every industry. Now, moving to gaming and ARPCs. Gaming revenue of 2.5 billion decreased 22 sequentially and 11 year on year.
Full-year revenue of 11.4 billion increased 9 year on year, and demand remains strong throughout the holiday. However, Q4 shipments were impacted by supply constraints. We expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 Series desktop and laptop GPUs are here.
Build for gamers, creators, and developers they fuse AI and graphics redefining visual computing, powered by the Blackwell architecture, fifth-generation Tensor cores, and fourth-generation RT cores and featuring UQ's400AI tops. These GPUs deliver a 2x performance leap and new AI-driven rendering including neuro shaders, digital human technologies, geometry, and lighting. The new DLSS 4 boost frame rates up to 8x with AI-driven frame generation, turning one rendered frame into three. It also features the industry's first real-time application of transformer models packing 2x more parameters and 4x to compute for unprecedented visual fidelity.
We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Max-Q technology that extends battery life by up to an incredible 40 . These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business. Revenue of 511 million was up 5 sequentially and 10 year on year.
Full-year revenue of 1.9 billion increased 21 year on year. Key industry verticals driving demand include automotive and healthcare. NVIDIA Technologies and generative AI are reshaping design, engineering, and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms from ANSYS, Cadence, and Siemens fueling demand for NVIDIA RTX workstations.
Now, moving to Automotive. Revenue was a record 570 million, up 27 sequentially and up 103 year on year. Full-year revenue of 1.7 billion increased 5 year on year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robotaxis.
At CES, we announced Toyota, the world's largest automaker will build its next-generation vehicles on NVIDIA Orin running the safety-certified NVIDIA DriveOS. We announced Aurora and Continental will deploy driverless trucks at scale powered by NVIDIA Drive Thor. Finally, our end-to-end autonomous vehicle platform NVIDIA Drive Hyperion has passed industry safety assessments like TUV SUD and TUV Rheinland, two of the industry's foremost authorities for automotive-grade safety and cybersecurity. NVIDIA is the first AV platform that received a comprehensive set of third-party assessments.
OK. Moving to the rest of the P L. GAAP gross margin was 73 and non-GAAP gross margin was 73.5 and down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA build chips multiple networking options, and for air and liquid-cooled data center.
We exceeded our expectations in Q4 in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low 70s. Initially, we are focused on expediting the manufacturing of Blackwell systems to meet strong customer demand as they race to build out Blackwell infrastructure. When fully ramped, we have many opportunities to improve the cost, and gross margin will improve and return to the mid-70s, late this fiscal year.
Sequentially, GAAP operating expenses were up 9 and non-GAAP operating expenses were 11 , reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned 8.1 billion to shareholders in the form of share repurchases and cash dividends. Let me turn to the outlook in the first quarter. Total revenue is expected to be 43 billion, plus or minus 2 .
Continuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth in both Data Center and Gaming. Within Data Center, we expect sequential growth from both compute and networking. GAAP and non-GAAP gross margins are expected to be 70.6 and 71 , respectively, plus or minus 50 basis points.
GAAP and non-GAAP operating expenses are expected to be approximately 5.2 billion and 3.6 billion, respectively. We expect full-year fiscal year '26 operating expenses to grow to be in the mid-30s. GAAP and non-GAAP other incoming expenses are expected to be an income of approximately 400 million. excluding gains and losses from nonmarketable and publicly held equity securities.
GAAP and non-GAAP tax rates are expected to be 17 , plus or minus 1 , excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website, including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community. We will be at the TD Cowen Health Care Conference in Boston on March 3 and at the Morgan Stanley Technology, Media, and Telecom Conference in San Francisco on March 5.
Please join us for our Annual GTC conference starting Monday, March 17 in San Jose, California. Jensen will deliver a news-packed keynote on March 18, and we will host a Q A session for our financial analysts for the next day, March 19. We look forward to seeing you at these events. Our earnings call to discuss the results for our first quarter of fiscal 2026 is scheduled for May 28, 2025.
We are going to open up the call, operator, to questions. If you could start that, that would be great.